Claude가 같은 실수를 반복하지는 않나요? 저도 그랬습니다

개발 중인 오픈소스의 벤치마크 점수를 Claude Code로 개선하려다 처참하게 실패했습니다.

평소처럼 Plan 모드로 시작했습니다.

하지만 이번 작업은 달랐습니다.

A로 구현하다가, 안 되면 B로 바꾸고, 다시 A로 돌아가는 루프에 빠집니다.

한 에이전트의 컨텍스트에 다 담기엔 작업이 너무 많았고, Auto Compact가 실행될 때마다 앞에서 내린 결정과 작업 내용이 희석됐습니다.

그래서 멀티에이전트 구조로 바꾸기로 했습니다.

전체 작업을 12개의 Task와 5개의 Phase로 재설계했습니다.

각 Task는 한 에이전트가 컨텍스트 안에서 완결할 수 있는 크기이며, 병렬 혹은 직렬로 처리됩니다.

핵심은 에이전트 간 지식 전달입니다.

예를 들어 Task 10 → Task 11의 Triage 최적화 실험 루틴은 5번을 반복했습니다.
1회차: Precision 27%, FP 110개.
2회차: Y-overlap 제거. Precision 36%로 개선, FP 72개.
...
5회차: 이미지 비율 조건 추가. Recall 100% 달성.

매 실험 결과는 다음 에이전트가 읽을 수 있게 기록됩니다.
새 에이전트는 이전 실험을 읽고, 실패한 방법을 다시 시도하지 않습니다.
에이전트는 결과를 분석하고 다음 실험 방법을 제안합니다.
저는 프로젝트 목적을 고려해서 무엇을 포기하고 무엇에 집중할지 의사결정을 내립니다.

결과입니다.

A-B-A 루프는 사라졌습니다. 

표 추론 점수는 0.49에서 0.93으로, 거의 2배가 됐습니다.

오픈소스 중 1위를 달성했습니다.

(벤치마크 이미지 참고)

멀티에이전트는 왜 성공했을까요?

현재 AI 에이전트의 병목은 지능이 아니라 기억입니다.

뛰어난 지능에 비해 컨텍스트 윈도우는 턱없이 작습니다.

기억의 구조를 엔지니어링 관점에서 설계하는 것부터 시작해야 합니다.

에이전트가 같은 실수를 반복한다면, 이 순서로 점검해보세요.

📋 체크리스트:

작업 분할

  ☐  한 에이전트가 컨텍스트 안에서 완결할 수 있는 크기인가?

  ☐  Task 간 의존관계가 명확한가?

지식 전달

  ☐  이전 에이전트의 작업 결과가 기록되어 있는가?

  ☐  필요한 스펙/문서가 컨텍스트에 들어가 있는가?

완료 조건

  ☐  에이전트가 스스로 명확한 성공 여부를 판단할 수 있는가?

  ☐  검증 방법(테스트, 명령어)이 명확한가?

Claude가 부족한 게 아닙니다. 기억의 구조가 부족했던 겁니다.

코드가 궁금하신 분들을 위해 링크 남깁니다.

https://github.com/opendataloader-project/opendataloader-pdf